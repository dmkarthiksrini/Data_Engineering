Document dated [15, Jan 2023]


This space is for the Data Engineering Zoomcamp Learning by [DataTalksClub](https://datatalks.club/)

[DataTalksClub Data Engineering GitHub](https://github.com/DataTalksClub/data-engineering-zoomcamp)

[DataTalksClub Youtube Playlist 1](https://www.youtube.com/watch?v=bkJZDmreIpA&list=PL3MmuxUbc_hKVX8VnwWCPaWlIHf1qmg8s) - With Airflow (From 2022 Zoomcamp Session)

[DataTalksClub Youtube Playlist 2](https://www.youtube.com/watch?v=-zpVha7bw5A&list=PL3MmuxUbc_hJjEePXIdE-LVUx_1ZZjYGW) - With Prefect *(this is an ongoing session on 2023 Jan)

(DataTalksClub)

##Objective 

Its a weekly online sessions focus on to develop oneself into a Data Engineering path. 

This programme Comprises of multiple online session which spreads over for 6 weeks focusing on different aspects of Data Engineering.

* Week 1	:	Introduction & Prerequisites
* Week 2	:	Ingestion & Orchestration
* Week 3	:	Data Warehouse
* Week 4	:	Analytics Engineering
* Week 5	:	Batch Processing
* Week 6	:	Stream Processing

End of the Programme we would be focuing on the standalone project to build a Data Pipeline based on the learning to get Certified.

[Technologies We will Learn](#Technologies)

###Week 1 Learning

**Required Software Installation**



### Technologies

* Technologies and sections which we will learn here
	* *GCP (Google Cloud Platform)* - Data Lake
	* *BigQuery* - Data Warehouse
	* *Docker* - Containerization
	* *SPARK* - Distributed Processing
	* *KAFKA* - Streaming
	* *DBT* - Data Transformation
	* *SQL* - Data Analysis & Exploration
	* *Airflow/Prefect* Pipeline orchestration

###FAQ's

* How Much time we need to spend on an Avg?
   * 3 to 4 hours in a week would suffice, and this varies based on everone's own  pace.
   
* Are we Building a project htrough this course?
   * We will be building a project in the course time with Taxi data of New York and will be performing Homework and at end we will build our own project at the end of the course to get certified.
* How can I get Internship's?
   * Get to know about current courses and create a strong foundation and showcase works on the LinkedIn, GitHub and other Public forums which the recruiters can access and see the interest we have towards the Field/Domain.
   
* What CLoud Technologies we can use?
   * GCP is the one we use predominantly, but it is also ok if we can use AWS. Main reason behind is the easy accessbility of Big Query. (Point the alternates for the Technologies)



* Thoughts related to Interview Perspective and Datastructures
	* Learning Algorithms and Data Structures helps a lot in the field and interview perspective


###Book Recommendations

[Designing Data Intensive Applications - Martin Kleppmann](https://learning.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/)

[Database Internals - Alex Petrov](https://learning.oreilly.com/library/view/database-internals/9781492040330/)

###Reference

DataTalksClub (no date) DataTalksClub/data-engineering-zoomcamp: Free Data Engineering Course!, GitHub. Available at: [https://github.com/DataTalksClub/data-engineering-zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp)  

